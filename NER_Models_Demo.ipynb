{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NER Models Demonstration\n\nThis notebook demonstrates the modular NER system for Russian cultural texts using various models including OpenAI API, spaCy, and DeepPavlov.\n\n## Features\n- **Unified Interface**: All models work through the same API (BaseNERModel)\n- **Direct Instantiation**: Simple, direct model creation without factory complexity\n- **Multiple Providers**: OpenAI, spaCy, DeepPavlov, and extensible for more\n- **Russian Focus**: Optimized for Russian cultural text NER\n- **Cross-platform**: Works in both Google Colab and local environments\n\n## Supported Models\n- **OpenAI**: GPT-4o, GPT-4, GPT-3.5-turbo (requires API key)\n- **spaCy**: Russian models (ru_core_news_sm, ru_spacy_ru_updated)\n- **DeepPavlov**: BERT-based Russian NER (ner_collection3_bert, ner_ontonotes_bert_mult)\n\n---\n**Instructions**: Run the setup cells below in order, then continue with the demonstration.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "**Run cells in order:**\n",
    "\n",
    "1. **Cell 2**: Common setup (repository cloning and dependencies)\n",
    "2. **Cell 3**: Environment configuration (Colab OR Local)\n",
    "3. **Cell 4**: Continue with the demo\n",
    "\n",
    "The setup will automatically detect your environment and configure accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mary-lev/NER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already in NER directory\n"
     ]
    }
   ],
   "source": [
    "# Environment setup and directory configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'NER':\n",
    "    print(\"Already in NER directory\")\n",
    "    ner_dir = current_dir\n",
    "else:\n",
    "    ner_dir = current_dir / 'NER'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Core libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import the NER models system - simplified without factory\nfrom utils.ner_models import (\n    BaseNERModel,\n    NERPrediction, \n    OpenAIModel,\n    SpacyModel,\n    DeepPavlovModel\n)\n\nprint(\"NER models system loaded successfully!\")\n\n# Show available model classes\nprint(f\"\\nAvailable model classes:\")\nprint(f\"   • OpenAIModel - for GPT-4o, GPT-4, GPT-3.5-turbo\")\nprint(f\"   • SpacyModel - for ru_core_news_sm, ru_spacy_ru_updated\")\nprint(f\"   • DeepPavlovModel - for ner_collection3_bert, ner_ontonotes_bert_mult\")\n\nprint(f\"\\nExample usage:\")\nprint(f\"   model = SpacyModel('ru_core_news_sm')\")\nprint(f\"   model.initialize()\")\nprint(f\"   predictions = model.predict(text)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 sample Russian cultural texts\n",
      "\n",
      "Sample text:\n",
      "   Встреча с писательницей Сюзанной Кулешовой. Презентация книги «Последний глоток ...\n"
     ]
    }
   ],
   "source": [
    "# Russian cultural texts for NER testing\n",
    "sample_texts = [\n",
    "    \"Встреча с писательницей Сюзанной Кулешовой. Презентация книги «Последний глоток божоле на двоих». Кулешова Сюзанна Марковна, член Союза писателей Санкт-Петербурга.\",\n",
    "    \"Большой поэтический вечер в самом начале весны! Дмитрий Артис, Борис Кутенков (Москва), Дмитрий Шабанов, Рахман Кусимов, Серафима Сапрыкина, Ася Анистратенко.\",\n",
    "    \"Вечер поэта Томаса Венцлова (США). Презентация книги 'Гранёный воздух' М.: ОГИ, 2002.\",\n",
    "    \"В рамках выставки «Максим Винавер. Пора возвращаться домой…». Спектакль по пьесе Максима Винавера «11 сентября».\",\n",
    "    \"Очередная встреча проекта «Открытая читка – юность». Куратор − Черток Анна\"\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(sample_texts)} sample Russian cultural texts\")\n",
    "print(\"\\nSample text:\")\n",
    "print(f\"   {sample_texts[0][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Models Demo\n",
    "Local models that don't require API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: The HTML index page being used (https://pypi.org/project/numpy/) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deeppavlov 1.7.0 requires numpy<1.24, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://admin:****@pypi.welltory.tech/pypi/\n",
      "Collecting ru-core-news-sm==3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q numpy==1.25.0 openai pandas matplotlib seaborn\n",
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def demo_spacy_model(model_name='ru_core_news_sm', text_index=0):\n    \"\"\"Demonstrate a spaCy model on sample text.\"\"\"\n    try:\n        print(f\"\\nTesting spaCy model: {model_name}...\")\n        \n        # Create and initialize model directly\n        model = SpacyModel(model_name)\n        model.initialize()\n        \n        # Get model info\n        info = model.get_model_info()\n        print(f\"Model: {info['model_name']} ({info['model_type']})\")\n        \n        # Test prediction\n        test_text = sample_texts[text_index]\n        print(f\"Text: {test_text[:100]}...\")\n        \n        predictions = model.predict(test_text)\n        \n        print(f\"Found {len(predictions)} entities:\")\n        for pred in predictions:\n            print(f\"   • '{pred.text}' [{pred.start}:{pred.end}] ({pred.entity_type})\")\n        \n        return model, predictions\n        \n    except Exception as e:\n        print(f\"Failed: {e}\")\n        return None, []\n\n# Test spaCy models\nprint(\"Testing spaCy models (local, no API key needed)\")\n\n# Check if spaCy is available and handle numpy compatibility issues\ntry:\n    import spacy\n    print(f\"spaCy version: {spacy.__version__}\")\n    \n    # Test the spaCy model\n    spacy_model, spacy_predictions = demo_spacy_model('ru_core_news_sm')\n    \nexcept ImportError:\n    print(\"spaCy not installed. Install with:\")\n    print(\"   !pip install spacy\")\n    print(\"   !python -m spacy download ru_core_news_sm\")\n    spacy_model, spacy_predictions = None, []\n    \nexcept ValueError as e:\n    if \"numpy.dtype size changed\" in str(e):\n        print(\"NumPy/spaCy compatibility issue detected.\")\n        print(\"Try restarting the runtime and running these commands:\")\n        print(\"   !pip install --upgrade numpy\")\n        print(\"   !pip install --no-build-isolation --force-reinstall spacy\")\n        print(\"   !python -m spacy download ru_core_news_sm\")\n        print(\"Then restart this notebook.\")\n    else:\n        print(f\"spaCy error: {e}\")\n    spacy_model, spacy_predictions = None, []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepPavlov Models Demo\n",
    "BERT-based models for high-accuracy Russian NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q deeppavlov"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nTesting DeepPavlov models (BERT-based, high accuracy)\")\nprint(\"Note: First run takes 5-10 minutes to download models\")\n\ndef demo_deeppavlov_model(model_name='ner_collection3_bert'):\n    \"\"\"Demonstrate a DeepPavlov model.\"\"\"\n    try:\n        print(f\"\\nTesting DeepPavlov model: {model_name}...\")\n        \n        # Create and initialize model directly\n        model = DeepPavlovModel(model_name)\n        model.initialize()\n        \n        # Test prediction\n        test_text = sample_texts[0]\n        predictions = model.predict(test_text)\n        \n        print(f\"Found {len(predictions)} entities:\")\n        for pred in predictions:\n            print(f\"   • '{pred.text}' [{pred.start}:{pred.end}] ({pred.entity_type})\")\n        \n        return model, predictions\n        \n    except Exception as e:\n        print(f\"DeepPavlov model failed: {e}\")\n        return None, []\n    \n# Uncomment to actually test (takes time on first run)\n# dp_model, dp_predictions = demo_deeppavlov_model('ner_collection3_bert')\n    \nprint(\"DeepPavlov demo skipped (uncomment above to run)\")\nprint(\"Expected performance: F1 ~0.78-0.81 on Russian cultural texts\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Models Demo\n",
    "API-based models with high flexibility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Check for OpenAI API key\nOPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', \"you_openai_api_key\")\nopenai_available = 'OPENAI_API_KEY' in os.environ\n\ndef demo_openai_model(model_name='gpt-4o'):\n    \"\"\"Demonstrate an OpenAI model.\"\"\"\n    try:\n        print(f\"\\nTesting OpenAI model: {model_name}...\")\n        \n        # Create and initialize model directly\n        model = OpenAIModel(model_name=model_name)\n        model.initialize()\n        \n        # Test prediction\n        test_text = sample_texts[0]\n        predictions = model.predict(test_text)\n        \n        print(f\"Found {len(predictions)} entities:\")\n        for pred in predictions:\n            print(f\"   • '{pred.text}' [{pred.start}:{pred.end}] ({pred.entity_type})\")\n        \n        return model, predictions\n        \n    except Exception as e:\n        print(f\"OpenAI model failed: {e}\")\n        return None, []\n\nif openai_available:\n    gpt_model, gpt_predictions = demo_openai_model('gpt-4o')\nelse:\n    print(\"OpenAI API key not set. Set OPENAI_API_KEY environment variable to test OpenAI models.\")\n    gpt_model, gpt_predictions = None, []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Multiple Text Processing Demo\nProcess multiple texts efficiently using simple iteration.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def process_multiple_texts_demo(model, texts):\n    \"\"\"Demonstrate processing multiple texts with a model.\"\"\"\n    try:\n        print(f\"\\nProcessing {len(texts)} texts with {model.model_name}...\")\n        \n        all_predictions = []\n        total_entities = 0\n        \n        for i, text in enumerate(texts):\n            try:\n                predictions = model.predict(text)\n                all_predictions.append(predictions)\n                total_entities += len(predictions)\n                \n                print(f\"Text {i+1}: {len(predictions)} entities\")\n                # Show first 2 entities from each text\n                for pred in predictions[:2]:\n                    print(f\"   • '{pred.text}' ({pred.entity_type})\")\n                if len(predictions) > 2:\n                    print(f\"   ... and {len(predictions) - 2} more\")\n                print()\n                    \n            except Exception as e:\n                print(f\"Error processing text {i+1}: {e}\")\n                all_predictions.append([])\n        \n        avg_entities = total_entities / len(texts)\n        print(f\"Summary: {total_entities} total entities ({avg_entities:.1f} avg per text)\")\n        \n        return all_predictions\n        \n    except Exception as e:\n        print(f\"Processing failed: {e}\")\n        return []\n\n# Demo multiple text processing with available models\nif 'spacy_model' in locals() and spacy_model:\n    multiple_results = process_multiple_texts_demo(spacy_model, sample_texts)\nelse:\n    print(\"No models available for multiple text processing demo\")\n    print(\"   Install spaCy or set OpenAI API key to test processing multiple texts\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Demo\n",
    "Compare different models on the same text."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def compare_models(text, models):\n    \"\"\"Compare multiple models on the same text.\"\"\"\n    print(f\"Comparing models on text:\")\n    print(f\"   '{text[:80]}...'\\n\")\n    \n    results = {}\n    \n    for model_name, model in models.items():\n        try:\n            predictions = model.predict(text)\n            results[model_name] = predictions\n            \n            print(f\"{model_name}: {len(predictions)} entities\")\n            for pred in predictions:\n                print(f\"   • '{pred.text}' ({pred.entity_type})\")\n            print()\n            \n        except Exception as e:\n            print(f\"{model_name}: Failed - {e}\\n\")\n            results[model_name] = []\n    \n    return results\n\n# Define models to compare (add/remove based on availability)\ncomparison_models = {}\n\n# Add spaCy if working\nif 'spacy_model' in locals() and spacy_model:\n    comparison_models['spacy'] = spacy_model\n\n# Add OpenAI if available\nif 'gpt_model' in locals() and gpt_model:\n    comparison_models['gpt-4o'] = gpt_model\n\nif comparison_models:\n    comparison_results = compare_models(sample_texts[1], comparison_models)\nelse:\n    print(\"No models available for comparison\")\n    print(\"   This would show side-by-side results from different models\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model Configuration\n",
    "Create models with custom settings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Example: Create OpenAI model with custom settings\nif openai_available:\n    print(\"Creating custom OpenAI model configuration...\")\n    \n    try:\n        # Custom model with specific parameters\n        custom_model = OpenAIModel(\n            model_name='gpt-4',\n            temperature=0.3,  # Lower temperature for more consistent results\n            max_tokens=500,\n            output_format='json'  # Structured JSON output\n        )\n        custom_model.initialize()\n        \n        print(f\"Custom model created: {custom_model}\")\n        print(f\"Configuration: {custom_model.get_model_info()['config']}\")\n        \n    except Exception as e:\n        print(f\"Custom model creation failed: {e}\")\n\n# Example: Create spaCy model with custom entity types\nprint(\"\\nCreating custom spaCy model configuration...\")\n\ntry:\n    custom_spacy = SpacyModel(\n        model_name='ru_core_news_sm',\n        entity_types={'PERSON', 'ORG', 'GPE'}  # Only these entity types\n    )\n    custom_spacy.initialize()\n    \n    print(f\"Custom spaCy model created\")\n    info = custom_spacy.get_model_info()\n    print(f\"Entity types: {info.get('config', {}).get('entity_types', 'All')}\")\n    \nexcept Exception as e:\n    print(f\"Custom spaCy model creation failed: {e}\")\n\nprint(\"\\nDirect model instantiation allows easy customization of any model type!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Evaluation Framework\n",
    "Show how NER results integrate with the evaluation system."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import evaluation utilities\nfrom utils import NEREvaluator\nfrom utils.common import safe_eval_list\n\ndef convert_to_evaluation_format(predictions):\n    \"\"\"Convert NER predictions to evaluation format.\"\"\"\n    return [pred.to_tuple() for pred in predictions]\n\n# Example: Process text and convert to evaluation format\nif 'spacy_model' in locals() and spacy_model:\n    print(\"Integration with evaluation framework:\")\n    \n    # Get predictions\n    test_text = sample_texts[0]\n    predictions = spacy_model.predict(test_text)\n    \n    # Convert to evaluation format (tuples)\n    eval_format = convert_to_evaluation_format(predictions)\n    \n    print(f\"Text: {test_text[:60]}...\")\n    print(f\"Model predictions: {len(predictions)} entities\")\n    print(f\"Evaluation format: {eval_format}\")\n    \n    # This format can be used directly with NEREvaluator\n    evaluator = NEREvaluator()\n    \n    # Example: Calculate metrics (would need ground truth for real evaluation)\n    print(\"\\nReady for evaluation pipeline integration!\")\n    print(\"For multiple texts, use simple iteration:\")\n    print(\"   for text in texts:\")\n    print(\"       predictions = model.predict(text)\")\n    print(\"       eval_format = convert_to_evaluation_format(predictions)\")\nelse:\n    print(\"Integration demo requires a working model\")\n    print(\"   This shows how to convert NER predictions to evaluation format\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary and Next Steps\n\nThis notebook demonstrated the **simplified NER system** with:\n\n### Features Shown\n- **Unified Interface**: All models use the same `BaseNERModel` API\n- **Direct Instantiation**: Simple, clear model creation without factory complexity\n- **Multiple Providers**: spaCy, OpenAI, DeepPavlov support\n- **Simple Processing**: Clean iteration for multiple texts\n- **Custom Configuration**: Flexible model parameters\n- **Evaluation Integration**: Compatible with existing evaluation framework\n\n### Available Models\n- **spaCy**: Local, no API key, good for development\n- **OpenAI**: High accuracy, flexible, requires API key\n- **DeepPavlov**: BERT-based, excellent for Russian, local\n\n### Usage Patterns\n```python\n# Simple usage - direct instantiation\nmodel = SpacyModel('ru_core_news_sm')\nmodel.initialize()\npredictions = model.predict(text)\n\n# Multiple texts - simple iteration\nfor text in texts:\n    predictions = model.predict(text)\n    # Process each text individually\n\n# Custom configuration\ncustom_model = OpenAIModel(model_name='gpt-4', temperature=0.3)\ncustom_model.initialize()\n```\n\n### Benefits of Simplified Design\n- **Cleaner API**: Only `predict()` method needed per model\n- **Easier debugging**: Direct stack traces, no batch complexity\n- **Type-safe**: IDE autocomplete and type checking\n- **Less complexity**: No batch processing overhead\n- **Clear responsibility**: Models focus on single text prediction\n\n### Next Steps\n1. **Install models**: spaCy Russian models, DeepPavlov (optional)\n2. **Set API keys**: OPENAI_API_KEY for OpenAI models (optional)\n3. **Run evaluation**: See `Evaluation_Analysis.ipynb` for model comparison\n4. **Extend system**: Add new model types using the `BaseNERModel` interface\n\n---\n\n**The simplified NER system provides a clean, maintainable foundation for Russian cultural text analysis!**",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}